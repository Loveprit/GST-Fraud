{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('gst_data1.csv', encoding='unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Data                  Type\n",
      "0  A contractor or supplier can commit fraud by k...  Fake Invoice Numbers\n",
      "1  False invoices refer to invoices for goods o...  Fake Invoice Numbers\n",
      "2  Knowingly typically is defined as:\\n\\nActual ...  Fake Invoice Numbers\n",
      "3  GENERAL RED FLAGS OF FALSE, INFLATED OR DUPLIC...  Fake Invoice Numbers\n",
      "4  Red flags of false invoices:\\n\\nNo receiving r...  Fake Invoice Numbers\n",
      "5  Red flags of inflated invoices:\\n\\nInvoice pri...  Fake Invoice Numbers\n",
      "6  Red flags of duplicate invoices:\\n\\nMultiple p...  Fake Invoice Numbers\n",
      "7  Identify and interview all complainants and co...  Fake Invoice Numbers\n",
      "8  Obtain the following documents and examine the...  Fake Invoice Numbers\n",
      "9  Do due diligence background checks on the cont...  Fake Invoice Numbers\n"
     ]
    }
   ],
   "source": [
    "df = df[pd.notnull(df['Type'])]\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "\n",
    "import logging\n",
    "import pandas as pd\n",
    "from numpy import random\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing text data\n",
    "#replace [/(){}\\[\\]\\|@,;] by space ' '\n",
    "#remove stopwords\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')   \n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(txt):\n",
    "    txt = BeautifulSoup(txt, \"lxml\").text # HTML decoding\n",
    "    txt = txt.lower() # lowercase text\n",
    "    txt = REPLACE_BY_SPACE_RE.sub(' ', txt) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    txt = BAD_SYMBOLS_RE.sub('', txt) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    txt = ' '.join(word for word in txt.split() if word not in STOPWORDS) # delete stopwors from text\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Data'] = df['Data'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Data']\n",
    "y = df['Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle dataset \n",
    "X, y = shuffle(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(df) * .7)\n",
    "train_posts = X[:train_size]\n",
    "train_tags = y[:train_size]\n",
    "test_posts = X[train_size:]\n",
    "test_tags = y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 1000\n",
    "tokenize = text.Tokenizer(num_words=max_words, char_level=False)\n",
    "tokenize.fit_on_texts(train_posts) # only fit on train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tokenize.texts_to_matrix(train_posts)\n",
    "x_test = tokenize.texts_to_matrix(test_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_tags)\n",
    "y_train = encoder.transform(train_tags)\n",
    "y_test = encoder.transform(test_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = np.max(y_train) + 1\n",
    "y_train = utils.to_categorical(y_train, num_classes)\n",
    "y_test = utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 5\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 927 samples, validate on 103 samples\n",
      "Epoch 1/5\n",
      "927/927 [==============================] - 1s 651us/step - loss: 1.6180 - accuracy: 0.3463 - val_loss: 1.2395 - val_accuracy: 0.5049\n",
      "Epoch 2/5\n",
      "927/927 [==============================] - 0s 538us/step - loss: 0.8377 - accuracy: 0.7152 - val_loss: 0.9553 - val_accuracy: 0.6311\n",
      "Epoch 3/5\n",
      "927/927 [==============================] - 0s 536us/step - loss: 0.4153 - accuracy: 0.8501 - val_loss: 1.2284 - val_accuracy: 0.6117\n",
      "Epoch 4/5\n",
      "927/927 [==============================] - 0s 529us/step - loss: 0.2991 - accuracy: 0.8986 - val_loss: 1.3563 - val_accuracy: 0.6311\n",
      "Epoch 5/5\n",
      "927/927 [==============================] - 0s 528us/step - loss: 0.2553 - accuracy: 0.8975 - val_loss: 1.3750 - val_accuracy: 0.6311\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442/442 [==============================] - 0s 54us/step\n",
      "Test accuracy: 0.6402714848518372\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
